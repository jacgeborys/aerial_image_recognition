{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyOZjPrjLB6gM7PJkjE45+2g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MuynVH_w2Md","executionInfo":{"status":"ok","timestamp":1728422163502,"user_tz":-120,"elapsed":104217,"user":{"displayName":"Jacek Gęborys","userId":"15708106607875074455"}},"outputId":"20dbb4c1-f974-4ab2-aeb1-5f3ef7229f52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","source":["# YOLO"],"metadata":{"id":"L4d0sKOF-mx-"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-etQx7MFYJ_","executionInfo":{"status":"ok","timestamp":1728339892013,"user_tz":-120,"elapsed":5967,"user":{"displayName":"Jacek Gęborys","userId":"15708106607875074455"}},"outputId":"810b0cc1-64e2-4981-922a-5e5ed6dcf1a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.7-py3-none-any.whl.metadata (34 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.3.7-py3-none-any.whl (882 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.0/883.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.7 ultralytics-thop-2.0.9\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import requests\n","from osgeo import gdal\n","import geopandas as gpd\n","from shapely.geometry import Point, box\n","from tqdm import tqdm\n","from ultralytics import YOLO\n","from io import BytesIO\n","\n","# Load the trained YOLO model\n","checkpoint_path = '/content/drive/MyDrive/aerial_image_recognition/img/train/Tokyo/yolov8_tokyo_checkpoint.pt'\n","model = YOLO(checkpoint_path)\n","print(\"Model loaded from checkpoint successfully!\")\n","\n","# Load the 'ramki.shp' layer using Geopandas\n","ramki_shp_path = '/content/drive/MyDrive/aerial_image_recognition/gis/shp/ramki.shp'\n","ramki_gdf = gpd.read_file(ramki_shp_path)\n","\n","# Select the specific area named 'srodmiescie' (adjust this filter for your case)\n","srodmiescie_gdf = ramki_gdf[ramki_gdf['name'] == 'srodmiescie']\n","\n","# Get the bounding box of 'srodmiescie'\n","minx, miny, maxx, maxy = srodmiescie_gdf.total_bounds\n","print(f\"Bounding box of srodmiescie: {minx}, {miny}, {maxx}, {maxy}\")\n","\n","# Define WMS parameters\n","wms_url = \"https://mapy.geoportal.gov.pl/wss/service/PZGIK/ORTO/WMS/StandardResolution\"\n","wms_params = {\n","    'service': 'WMS',\n","    'version': '1.3.0',\n","    'request': 'GetMap',\n","    'layers': 'ORTO',\n","    'styles': '',\n","    'crs': 'EPSG:3857',  # Match to your projected CRS (Web Mercator)\n","    'bbox': f'{minx},{miny},{maxx},{maxy}',  # Update for each tile\n","    'width': 1200,  # Set the image size matching your model\n","    'height': 1200,\n","    'format': 'image/tiff'\n","}\n","\n","# Define an empty GeoDataFrame for storing car/truck detections\n","car_centroids_gdf = gpd.GeoDataFrame(columns=['geometry', 'class', 'confidence'])\n","\n","# Loop through and fetch tiles from the WMS server\n","stride = 600  # Adjust stride for partial overlap\n","tile_size = 1200\n","\n","# Split the area into smaller tiles based on stride and tile size\n","x_coords = list(range(int(minx), int(maxx), stride))\n","y_coords = list(range(int(miny), int(maxy), stride))\n","\n","total_tiles = len(x_coords) * len(y_coords)\n","\n","with tqdm(total=total_tiles, desc=\"Processing Tiles\") as pbar:\n","    for x in x_coords:\n","        for y in y_coords:\n","            # Adjust bounding box for each tile\n","            tile_bbox = f'{x},{y},{x+tile_size},{y+tile_size}'\n","            wms_params['bbox'] = tile_bbox\n","\n","            # Request the tile from WMS\n","            response = requests.get(wms_url, params=wms_params)\n","\n","            if response.status_code == 200:\n","                # Load the image into OpenCV\n","                img_data = BytesIO(response.content)\n","                img = gdal.Open(img_data).ReadAsArray()\n","                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","\n","                # Run YOLO inference on the tile\n","                results = model(img)\n","\n","                # Extract bounding boxes and append to GeoDataFrame\n","                for box in results[0].boxes:\n","                    if box.cls in [0, 1] and box.conf > 0.4:  # Only consider cars/trucks\n","                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n","                        centroid_x = (x1 + x2) / 2 + x  # Adjust based on the tile's position\n","                        centroid_y = (y1 + y2) / 2 + y\n","\n","                        # Append the result to the GeoDataFrame\n","                        car_centroids_gdf = car_centroids_gdf.append({\n","                            'geometry': Point(centroid_x, centroid_y),\n","                            'class': 'Car' if box.cls == 0 else 'Truck',\n","                            'confidence': box.conf.item()\n","                        }, ignore_index=True)\n","\n","            pbar.update(1)\n","\n","# Set CRS to match the WMS (EPSG:3857 for Web Mercator)\n","car_centroids_gdf.set_crs(epsg=3857, inplace=True)\n","\n","# Save the results to a GeoJSON file\n","output_geojson_path = '/content/drive/MyDrive/aerial_image_recognition/gis/car_centroids_2.geojson'\n","car_centroids_gdf.to_file(output_geojson_path, driver='GeoJSON')\n","\n","print(f\"Car and truck centroids saved to {output_geojson_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBFmimBOw7bw","executionInfo":{"status":"ok","timestamp":1728340001045,"user_tz":-120,"elapsed":4343,"user":{"displayName":"Jacek Gęborys","userId":"15708106607875074455"}},"outputId":"b90d4a76-22f0-45e9-c2bd-8b0ffa48ddec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded from checkpoint successfully!\n","Bounding box of srodmiescie: 20.981389979899493, 52.22652066381057, 21.029888441054208, 52.25128290846448\n"]},{"output_type":"stream","name":"stderr","text":["Processing Tiles: 0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Car and truck centroids saved to /content/drive/MyDrive/aerial_image_recognition/gis/car_centroids_2.geojson\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# ONNX"],"metadata":{"id":"pq9CLeg_-j15"}},{"cell_type":"code","source":["!pip install onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nt-Wnwb_QM_","executionInfo":{"status":"ok","timestamp":1728422193882,"user_tz":-120,"elapsed":4964,"user":{"displayName":"Jacek Gęborys","userId":"15708106607875074455"}},"outputId":"5339be85-ea47-4817-91de-1c9e1342e86a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnxruntime\n","  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.3)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2\n"]}]},{"cell_type":"code","source":["import onnxruntime as ort\n","import cv2\n","import os\n","import geopandas as gpd\n","from shapely.geometry import Point\n","from tqdm import tqdm\n","from osgeo import gdal\n","import numpy as np\n","\n","# Load the ONNX model\n","onnx_model_path = '/content/drive/MyDrive/aerial_image_recognition/models/car_aerial_detection_yolo7_ITCVD_deepness.onnx'\n","session = ort.InferenceSession(onnx_model_path)\n","print(\"ONNX model loaded successfully!\")\n","\n","# Path to the large GeoTIFF map image\n","geo_tiff_path = '/content/drive/MyDrive/aerial_image_recognition/img/geotiff/srodmiescie.tiff'\n","\n","# Load the GeoTIFF as a large image and extract the geotransform\n","dataset = gdal.Open(geo_tiff_path)\n","geotransform = dataset.GetGeoTransform()\n","img = dataset.ReadAsArray().transpose((1, 2, 0))  # Read GeoTIFF directly to preserve georeferencing\n","h, w = img.shape[:2]\n","\n","# Ensure the image has 3 channels (RGB), if it has 4 (RGBA), remove the alpha channel\n","if img.shape[2] == 4:\n","    img = img[:, :, :3]\n","\n","# Define window size and stride based on the larger scale\n","window_size = 1200  # Adjusted size for better coverage\n","stride = int(window_size * 0.91)  # 9% overlap between tiles\n","\n","# Initialize an empty list to store car/truck centroids and confidences\n","car_truck_centroids = []\n","\n","# Calculate the total number of tiles for the progress bar\n","total_tiles = ((h - window_size) // stride + 1) * ((w - window_size) // stride + 1)\n","\n","# Function to convert pixel coordinates to geographic coordinates\n","def pixel_to_geo(pixel_x, pixel_y, geotransform):\n","    geo_x = geotransform[0] + pixel_x * geotransform[1] + pixel_y * geotransform[2]\n","    geo_y = geotransform[3] + pixel_x * geotransform[4] + pixel_y * geotransform[5]\n","    return geo_x, geo_y\n","\n","# Function to run inference using ONNX model\n","def run_onnx_inference(window):\n","    # Preprocess the image (resize to the expected input size, i.e., 640x640 for ONNX model)\n","    original_size = window.shape[:2]\n","    input_image = cv2.resize(window, (640, 640))  # Resize to model input size\n","    input_image = np.transpose(input_image, (2, 0, 1))  # Change from HWC to CHW format\n","    input_image = input_image.astype(np.float32) / 255.0  # Normalize image\n","    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n","\n","    # Run inference\n","    input_name = session.get_inputs()[0].name\n","    outputs = session.run(None, {input_name: input_image})\n","\n","    return outputs, original_size\n","\n","# Function to extract bounding boxes, centroids, and confidence scores from the ONNX model output\n","def process_onnx_output(outputs, original_size):\n","    bounding_boxes = outputs[0][0]  # Assuming the output is structured similarly to your previous example\n","\n","    centroids = []\n","    for bbox in bounding_boxes:\n","        x1, y1, x2, y2, confidence, class_id = bbox\n","        if confidence > 0.5:  # Only consider high-confidence detections\n","            # Calculate the centroid in the resized window (640x640 space)\n","            centroid_x = (x1 + x2) / 2\n","            centroid_y = (y1 + y2) / 2\n","\n","            # Scale the centroid back to the original window size\n","            scale_x = original_size[1] / 640.0\n","            scale_y = original_size[0] / 640.0\n","            centroid_x *= scale_x\n","            centroid_y *= scale_y\n","\n","            centroids.append((centroid_x, centroid_y, class_id, confidence))\n","\n","    return centroids\n","\n","# Loop through the image using a sliding window approach with a progress bar\n","with tqdm(total=total_tiles, desc=\"Processing Entire Image\") as pbar:\n","    for y in range(0, h, stride):\n","        for x in range(0, w, stride):\n","            # Extract the current window (ensure you don't go beyond image borders)\n","            window = img[y:min(y + window_size, h), x:min(x + window_size, w)]\n","\n","            # Run inference using ONNX model\n","            outputs, original_size = run_onnx_inference(window)\n","\n","            # Process the ONNX output and get centroids\n","            centroids = process_onnx_output(outputs, original_size)\n","\n","            # Loop through the centroids and convert pixel coordinates to geographic coordinates\n","            for centroid_x, centroid_y, class_id, confidence in centroids:\n","                # Adjust the centroid based on the window's position in the full image\n","                centroid_x += x\n","                centroid_y += y\n","\n","                # Convert pixel coordinates to geographic coordinates\n","                geo_x, geo_y = pixel_to_geo(centroid_x, centroid_y, geotransform)\n","\n","                # Store the centroid, class (Car/Truck), and confidence\n","                car_truck_centroids.append({\n","                    'geometry': Point(geo_x, geo_y),\n","                    'class': 'Car' if class_id == 0 else 'Truck',\n","                    'confidence': confidence\n","                })\n","\n","            # Update the progress bar\n","            pbar.update(1)\n","\n","# Create a GeoDataFrame from the centroids list\n","car_truck_gdf = gpd.GeoDataFrame(car_truck_centroids)\n","\n","# Set the CRS to match the GeoTIFF CRS\n","car_truck_gdf.set_crs(epsg=3857, inplace=True)  # Using EPSG:3857 for Web Mercator CRS\n","\n","# Check if the output directory exists, if not, create it\n","output_dir = '/content/drive/MyDrive/aerial_image_recognition/gis/shp/'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Save the car and truck centroids, class, and confidence as a GeoJSON\n","output_geojson_path = os.path.join(output_dir, 'car_centroids_onnx.geojson')\n","car_truck_gdf.to_file(output_geojson_path, driver='GeoJSON')\n","\n","print(f\"Car and truck centroids with confidence saved as GeoJSON to: {output_geojson_path}\")\n"],"metadata":{"id":"uo5iISOfw7Y0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728427025573,"user_tz":-120,"elapsed":66599,"user":{"displayName":"Jacek Gęborys","userId":"15708106607875074455"}},"outputId":"8a5d92b5-2a3d-49c6-adf7-d07075155f57"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["ONNX model loaded successfully!\n"]},{"output_type":"stream","name":"stderr","text":["Processing Entire Image: 480it [01:02,  7.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Car and truck centroids with confidence saved as GeoJSON to: /content/drive/MyDrive/aerial_image_recognition/gis/shp/car_centroids_onnx.geojson\n"]}]}]}